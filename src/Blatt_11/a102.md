# Die drei Arten der parallelen Speicherung


## 1. **Distributed Memory (Verteilte Speicherung)**

Jeder Prozessor verfügt über einen eigenen, **lokalen Speicher**. Es gibt **keinen gemeinsamen Speicherbereich**.

- **Kommunikation**: erfolgt über ein Netzwerk mittels **Message Passing** (z.B. MPI).
- **Beispiel**: Cloud-Computing-Systeme, bei denen Knoten Datenpakete über das Netzwerk austauschen.
- **Vorteil**: Skalierbarkeit bei großen Systemen.
- **Nachteil**: Höherer Aufwand bei der Synchronisation und Datenübertragung.

**Beispiel**: Zwei Server in einem Rechenzentrum führen gemeinsam eine Simulation durch. Sie teilen Zwischenergebnisse über Netzwerk-Nachrichten mit.
---
## 2. **Shared Memory (Geteilter Speicher)**
Alle Prozessoren greifen auf einen **gemeinsamen Speicher** zu. Kommunikation erfolgt über **gemeinsam genutzte Speicherbereiche**.

- **Kommunikation**: über **Shared Variables**, oft mit Hilfe von Synchronisationsmechanismen (z.B. Mutex, Semaphore).
- **Beispiel**: Multithreading auf einem typischen modernen **Multicore-Prozessor**.
- **Vorteil**: Effizienter Datenaustausch.
- **Nachteil**: Zugriffskonflikte und Synchronisationsprobleme (Race Conditions).

**Beispiel**: Ein Bildbearbeitungsprogramm nutzt mehrere Threads, um verschiedene Bildbereiche gleichzeitig zu verarbeiten.
---
## 3. **Hybride Systeme**

Kombination aus Distributed und Shared Memory:
- **Innerhalb eines Knotens**: Shared Memory zwischen Threads.
- **Zwischen Knoten**: Message Passing.
- **Beispiel**: High-Performance-Cluster oder Cloud-Dienste mit mehreren Nodes und Multithreading je Node.
- **Vorteil**: Skalierbarkeit **und** effiziente lokale Kommunikation.
- **Nachteil**: Komplexe Programmierung.

**Beispiel**: Wettermodellierung auf einem Cluster, wobei jeder Rechenknoten mehrere Kerne hat und gleichzeitig mit anderen Knoten kommunizieren muss.

